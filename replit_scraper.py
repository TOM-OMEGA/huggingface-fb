import os
import json
import time
import asyncio
import threading
from flask import Flask, jsonify, request, abort
from pyppeteer import launch

# =========================================================
# ğŸ§± Keep-alive Flaskï¼ˆé˜² Render ç¡çœ ï¼‰
# =========================================================
keep_alive_app = Flask("keep_alive")

@keep_alive_app.route('/')
def keep_alive_home():
    return "âœ… Keep-alive server is running!", 200

def run_keep_alive():
    port = int(os.getenv("KEEP_ALIVE_PORT", 8081))
    print(f"ğŸŒ™ Keep-alive Flask running on port {port}")
    keep_alive_app.run(host="0.0.0.0", port=port)

def keep_alive():
    t = threading.Thread(target=run_keep_alive)
    t.daemon = True
    t.start()

# =========================================================
# âš™ï¸ ä¸» Flask æœå‹™
# =========================================================
app = Flask(__name__)

COOKIE_FILE = "/tmp/fb_state.json"
POSTS_FILE = "/tmp/posts.json"
API_KEY = os.getenv("RENDER_API_KEY")
FB_URL = os.getenv("FB_PAGE_URL", "https://www.facebook.com/LARPtimes/")

# =========================================================
# ğŸ§© åˆå§‹åŒ– Cookie
# =========================================================
def init_cookie_from_env():
    fb_cookie = os.getenv("FB_COOKIES")
    if fb_cookie and not os.path.exists(COOKIE_FILE):
        try:
            data = json.loads(fb_cookie)
            with open(COOKIE_FILE, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print("âœ… FB Cookie å·²å¾ç’°å¢ƒè®Šæ•¸å¯«å…¥ /tmp/fb_state.json")
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•è§£æ FB_COOKIES: {e}")

# =========================================================
# ğŸ”’ é©—è­‰å®‰å…¨é‡‘é‘°
# =========================================================
@app.before_request
def verify_api_key():
    if request.path in ["/", "/status"]:
        return
    key = request.headers.get("Authorization")
    if not key or key != f"Bearer {API_KEY}":
        print(f"â›” æœªæˆæ¬Šçš„å­˜å–ï¼š{request.path}")
        abort(401)

# =========================================================
# ğŸ“‚ è³‡æ–™å­˜å–
# =========================================================
def save_posts(posts):
    with open(POSTS_FILE, "w", encoding="utf-8") as f:
        json.dump(posts, f, ensure_ascii=False, indent=2)

def load_posts():
    if not os.path.exists(POSTS_FILE):
        return []
    try:
        with open(POSTS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return []

# =========================================================
# ğŸ” è‡ªå‹•åµæ¸¬ Chrome è·¯å¾‘
# =========================================================
def find_chrome_path():
    paths = [
        "/usr/bin/google-chrome",
        "/usr/bin/chromium",
        "/usr/bin/chromium-browser",
        "/opt/google/chrome/chrome"
    ]
    for path in paths:
        if os.path.exists(path):
            print(f"ğŸ§­ åµæ¸¬åˆ° Chrome åŸ·è¡Œè·¯å¾‘ï¼š{path}")
            return path
    print("âš ï¸ æœªæ‰¾åˆ° Chromeï¼Œè«‹ç¢ºèª Dockerfile æœ‰å®‰è£ google-chrome-stable")
    return None

# =========================================================
# ğŸ•·ï¸ Facebook çˆ¬èŸ²ä¸»ç¨‹å¼
# =========================================================
async def scrape_facebook_async():
    print(f"ğŸš€ é–‹å§‹çˆ¬å–ï¼š{FB_URL}")

    if not os.path.exists(COOKIE_FILE):
        print("âŒ æ‰¾ä¸åˆ° fb_state.jsonï¼Œè«‹å…ˆä¸Šå‚³ Cookie")
        return []

    try:
        chrome_path = find_chrome_path()
        if not chrome_path:
            return []

        print("ğŸ§± å•Ÿå‹• Chromium (Pyppeteer æ¨¡å¼)...")
        browser = await launch(
            headless=True,
            executablePath=chrome_path,
            args=[
                "--no-sandbox",
                "--disable-dev-shm-usage",
                "--disable-gpu",
                "--disable-blink-features=AutomationControlled",
                "--window-size=1280,800"
            ]
        )
        page = await browser.newPage()

        # ç§»é™¤ "navigator.webdriver" å±¬æ€§ (åçˆ¬èŸ²é˜²è­·)
        await page.evaluateOnNewDocument("""
            () => {
                Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            }
        """)

        # è¼‰å…¥ Cookie
        with open(COOKIE_FILE, "r", encoding="utf-8") as f:
            cookie_data = json.load(f)
        cookies = cookie_data.get("cookies", [])
        await page.setCookie(*cookies)

        print(f"ğŸŒ å‰å¾€ï¼š{FB_URL}")
        await page.goto(FB_URL, {"timeout": 120000, "waitUntil": "networkidle2"})

        html = await page.content()
        if "ç™»å…¥ Facebook" in html or "login" in page.url:
            print("âš ï¸ Cookie å·²å¤±æ•ˆæˆ–æœªç™»å…¥ç‹€æ…‹")
            await browser.close()
            return []

        # æ»¾å‹•è¼‰å…¥æ›´å¤šå…§å®¹
        for i in range(3):
            print(f"ğŸ”„ æ»¾å‹•è¼‰å…¥ç¬¬ {i+1}/3 æ¬¡...")
            await page.evaluate("window.scrollBy(0, document.body.scrollHeight)")
            await asyncio.sleep(4)

        posts = []
        elements = await page.querySelectorAll('div[role="article"]')
        print(f"ğŸ“‘ åµæ¸¬åˆ° {len(elements)} å‰‡è²¼æ–‡å…ƒç´ ")

        for idx, el in enumerate(elements):
            try:
                text_el = await el.querySelector('div[data-ad-preview="message"], span[dir="auto"]')
                text = await page.evaluate("(el) => el.innerText", text_el) if text_el else ""
                img_el = await el.querySelector('img[src*=\"scontent\"]')
                img = await page.evaluate("(el) => el.src", img_el) if img_el else None
                if text or img:
                    posts.append({
                        "content": text.strip(),
                        "image": img,
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    })
                    print(f"ğŸ“ ç¬¬ {idx+1} å‰‡è²¼æ–‡æ“·å–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ ç¬¬ {idx+1} å‰‡è²¼æ–‡è§£æéŒ¯èª¤: {e}")

        await browser.close()
        print(f"âœ… çˆ¬å–å®Œæˆï¼Œå…± {len(posts)} å‰‡è²¼æ–‡")
        save_posts(posts)
        return posts

    except Exception as e:
        print(f"âŒ çˆ¬èŸ²åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
        return []

# =========================================================
# ğŸ“¡ API è·¯ç”±
# =========================================================
@app.route("/upload", methods=["POST"])
def upload_cookie():
    try:
        data = request.get_json()
        with open(COOKIE_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print("âœ… Cookie å·²æ›´æ–°")
        return jsonify({"message": "âœ… Cookie å·²æ›´æ–°"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/run", methods=["GET"])
def run_scraper():
    print("ğŸŸ¢ æ”¶åˆ° /run è«‹æ±‚ï¼Œå•Ÿå‹•èƒŒæ™¯çˆ¬èŸ²åŸ·è¡Œç·’")

    def worker():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        posts = loop.run_until_complete(scrape_facebook_async())
        print(f"âœ… çˆ¬èŸ²å®Œæˆï¼Œå…± {len(posts)} å‰‡è²¼æ–‡")
        loop.close()

    threading.Thread(target=worker, daemon=True).start()
    return jsonify({"message": "ğŸš€ çˆ¬èŸ²å·²å•Ÿå‹•"}), 200


@app.route("/status", methods=["GET"])
def get_status():
    posts = load_posts()
    return jsonify({
        "fb_state.json": os.path.exists(COOKIE_FILE),
        "posts_count": len(posts),
        "recent_posts": posts[-3:] if posts else []
    }), 200


@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "service": "Render FB Scraper (Pyppeteer)",
        "status": "online"
    }), 200

# =========================================================
# ğŸš€ ä¸»ç¨‹å¼
# =========================================================
if __name__ == "__main__":
    os.environ["KEEP_ALIVE_PORT"] = "8081"
    keep_alive()
    init_cookie_from_env()

    port = int(os.getenv("PORT", 5000))
    print(f"ğŸŒ ä¸» Flask æœå‹™å•Ÿå‹•æ–¼ port {port}")
    app.run(host="0.0.0.0", port=port, use_reloader=False)
