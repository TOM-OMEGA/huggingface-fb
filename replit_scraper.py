import os
import json
import threading
import time
from flask import Flask, jsonify, request
from pyppeteer import launch
import asyncio

# =========================================================
# ğŸ§± é˜²ç¡çœ  Flask ä¼ºæœå™¨ï¼ˆç¨ç«‹åŸ ï¼‰
# =========================================================
keep_alive_app = Flask("keep_alive")

@keep_alive_app.route('/')
def keep_alive_home():
    return "âœ… Keep-alive server is running!", 200

def run_keep_alive():
    port = int(os.getenv("KEEP_ALIVE_PORT", 8081))
    keep_alive_app.run(host="0.0.0.0", port=port)

def keep_alive():
    t = threading.Thread(target=run_keep_alive)
    t.daemon = True
    t.start()

# =========================================================
# âš™ï¸ ä¸» Flask API
# =========================================================
app = Flask(__name__)
POSTS_FILE = "posts.json"
COOKIE_FILE = "fb_state.json"


# =========================================================
# ğŸ“‚ å„²å­˜èˆ‡è®€å–
# =========================================================
def save_posts(posts):
    with open(POSTS_FILE, "w", encoding="utf-8") as f:
        json.dump(posts, f, ensure_ascii=False, indent=2)

def load_posts():
    if not os.path.exists(POSTS_FILE):
        return []
    try:
        with open(POSTS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return []


# =========================================================
# ğŸ¤– Facebook çˆ¬èŸ²ä¸»ç¨‹å¼ï¼ˆä½¿ç”¨ Pyppeteerï¼‰
# =========================================================
async def scrape_facebook_async():
    print("ğŸš€ å•Ÿå‹• Facebook çˆ¬èŸ²")

    if not os.path.exists(COOKIE_FILE):
        print("âŒ ç¼ºå°‘ fb_state.jsonï¼Œè«‹å…ˆä¸Šå‚³ Cookie")
        return

    fb_url = os.getenv("FB_PAGE_URL", "https://www.facebook.com/appledaily.tw/posts")

    try:
        print("ğŸ§± å•Ÿå‹• Chromium (Pyppeteer æ¨¡å¼)...")
        browser = await launch(
            headless=True,
            executablePath="/usr/bin/google-chrome",
            args=["--no-sandbox", "--disable-dev-shm-usage", "--disable-gpu"]
        )
        page = await browser.newPage()

        # è¼‰å…¥ cookie
        with open(COOKIE_FILE, "r", encoding="utf-8") as f:
            cookie_data = json.load(f)
        cookies = cookie_data.get("cookies", [])
        await page.setCookie(*cookies)

        print(f"ğŸŒ å‰å¾€ï¼š{fb_url}")
        await page.goto(fb_url, {"timeout": 120000, "waitUntil": "networkidle2"})

        # æ¨¡æ“¬æ»¾å‹•ä»¥è¼‰å…¥æ›´å¤šå…§å®¹
        for i in range(3):
            await page.evaluate("window.scrollBy(0, document.body.scrollHeight)")
            await asyncio.sleep(3)

        posts = []
        elements = await page.querySelectorAll('div[role="article"]')
        for el in elements:
            text_el = await el.querySelector('div[data-ad-preview="message"], span[dir="auto"]')
            text = await page.evaluate("(el) => el.innerText", text_el) if text_el else ""
            img_el = await el.querySelector('img[src*="scontent"]')
            img = await page.evaluate("(el) => el.src", img_el) if img_el else None
            if text or img:
                posts.append({
                    "content": text.strip(),
                    "image": img,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                })

        await browser.close()
        print(f"âœ… å®Œæˆï¼Œæ“·å– {len(posts)} å‰‡è²¼æ–‡")
        save_posts(posts)
        return posts

    except Exception as e:
        print(f"âŒ åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")


def scrape_facebook():
    asyncio.run(scrape_facebook_async())


# =========================================================
# ğŸ“¡ API è·¯ç”±
# =========================================================
@app.route("/upload", methods=["POST"])
def upload_cookie():
    try:
        data = request.get_json()
        with open(COOKIE_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print("âœ… Cookie å·²æ›´æ–°")
        return jsonify({"message": "âœ… Cookie å·²æ›´æ–°"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/run", methods=["GET"])
def run_scraper():
    threading.Thread(target=scrape_facebook).start()
    return jsonify({"message": "ğŸš€ çˆ¬èŸ²å·²å•Ÿå‹•"}), 200


@app.route("/status", methods=["GET"])
def status():
    posts = load_posts()
    return jsonify({
        "fb_state.json": os.path.exists(COOKIE_FILE),
        "posts_count": len(posts),
        "recent_posts": posts[-3:] if posts else []
    }), 200


@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "service": "Railway FB Scraper (Pyppeteer)",
        "status": "online"
    }), 200


# =========================================================
# ğŸš€ ä¸»ç¨‹å¼å•Ÿå‹•
# =========================================================
if __name__ == "__main__":
    os.environ["KEEP_ALIVE_PORT"] = "8081"
    keep_alive()

    port = int(os.getenv("PORT", 5000))
    print(f"ğŸŒ ä¸» Flask æœå‹™å•Ÿå‹•æ–¼ port {port}")
    app.run(host="0.0.0.0", port=port, use_reloader=False)
